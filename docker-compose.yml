###################################
#
# make start-all-local
#
###################################

# docker volume rm $(docker volume ls -q -f "dangling=true")

services:
  warg-server:
    image: "ghcr.io/reecepbcups/warg-registry:v0.9.3"
    container_name: "warg-server"
    platform: linux/amd64
    environment:
      WARG_OPERATOR_KEY: ecdsa-p256:I+UlDo0HxyBBFeelhPPWmD+LnklOpqZDkrFP5VduASk=
      WARG_NAMESPACE: example
      WKG_REGISTRY: http://localhost:5000
      WARG_CONTENT_BASE_URL: http://localhost:8090
      WARG_LISTEN: 0.0.0.0:8090
      WARG_VERBOSE: 1
    ports:
      - 8090:8090
    command: ["--rm"]

  ipfs:
    image: ipfs/kubo:v0.37.0
    container_name: ipfs
    network_mode: host
    ports:
      - "4001:4001"
      - "4001:4001/udp"
      - "8080:8080"
      - "5001:5001"
    stop_signal: SIGKILL
    command: daemon
    restart: unless-stopped

  # ollama:
  #   image: ollama/ollama:0.11.0
  #   container_name: "ollama"
  #   stop_signal: SIGKILL
  #   ports:
  #     - "11434:11434"
  #   volumes:
  #     - ollama-data:/root/.ollama
  #   entrypoint: ["/bin/sh", "-c"]
  #   command:
  #     - |
  #       ollama serve &
  #       sleep 5
  #       ollama pull llama3.2
  #       wait
  #   restart: unless-stopped

volumes:
  ollama-data:
